---

layout: post
title: pytorch
category: 架构
tags: MachineLearning
keywords:  pytorch

---

## 简介

* TOC
{:toc}


[这是我见过最好的NumPy图解教程！](https://mp.weixin.qq.com/s/77aq0JQs8SX6molSxewOdQ)NumPy是Python中用于数据分析、机器学习、科学计算的重要软件包。它极大地简化了向量和矩阵的操作及处理。《用python实现深度学习框架》用python 和numpy 实现了一个深度学习框架MatrixSlow
1. 支持计算图的搭建、前向、反向传播
2. 支持多种不同类型的节点，包括矩阵乘法、加法、数乘、卷积、池化等，还有若干激活函数和损失函数。比如向量操作pytorch 跟numpy 函数命名都几乎一样
3. 提供了一些辅助类和工具函数，例如构造全连接层、卷积层和池化层的函数、各种优化器类、单机和分布式训练器类等，为搭建和训练模型提供便利

安装 [Ubuntu 20.04 下的 PyTorch（CPU版）安装及配置](https://www.limfx.pro/readarticle/1662/ubuntu-2004-xia-de-pytorchcpuban-an-zhuang-ji-pei-zhi-)

## 什么是pytorch

[Pytorch详细介绍(上)](https://mp.weixin.qq.com/s/YDNX49NGWMqkLML0_k0Phg)Pytorch是一个很容易学习、使用和部署的深度学习库。PyTorch同时提供了更高性能的C++ API（libtorch）。Pytorch使用Tensor作为核心数据结构，Tensor（张量）是神经网络世界的Numpy，其类似与Numpy数组，但是又不同于Numpy数组。为了提高Tensor的计算速度，有大量的硬件和软件为了Tensor运算进行支持和优化。总得来说，Tensor具有如下特点：

1. 具有类似Numpy的数据，Tensor可以与Numpy共享内存；
2. 可以指定计算设备，例如，设定Tensor是在CPU上计算，还是在GPU上计算；
3. Tensor可微分。
4. 通过访问张量的device属性可以获取张量所在的设备

PyTorch工作流以及与每个步骤相关联的重要模块

![](/public/upload/machine/pytorch_process.png)


## 数据读取

PyTorch 使用 Dataset 类与 DataLoader 类的组合，来得到数据迭代器。
1. Dataset用来表示数据集。通过继承 Dataset 类来自定义数据集的格式、大小和其它属性，后面就可以供 DataLoader 类直接使用。
2. 如果数据量很大，考虑到内存有限、I/O 速度等问题，在训练过程中不可能一次性的将所有数据全部加载到内存中，也不能只用一个进程去加载，所以就需要多进程、迭代加载，而 DataLoader 就是基于这些需要被设计出来的。DataLoader 是一个迭代器，最基本的使用方法就是传入一个 Dataset 对象，它会根据参数 batch_size 的值生成一个 batch 的数据，节省内存的同时，它还可以实现多进程、数据打乱等处理。

```python
from torch.utils.data import DataLoader
tensor_dataloader = DataLoader(dataset=my_dataset, # 传入的数据集, 必须参数
                               batch_size=2,       # 输出的batch大小
                               shuffle=True,       # 数据是否打乱
                               num_workers=0)      # 进程数, 0表示只有主进程

# 以循环形式输出
for data, target in tensor_dataloader: 
    print(data, target)
```


Torchvision 库中的torchvision.datasets包中提供了丰富的图像数据集的接口。常用的图像数据集，例如 MNIST、COCO 等，这个模块都为我们做了相应的封装。
它的工作方式是先从网络上把数据集下载到用户指定目录，然后再用它的加载器把数据集加载到内存中。最后，把这个加载后的数据集作为对象返回给用户。

```python

# 以MNIST为例
import torchvision
mnist_dataset = torchvision.datasets.MNIST(root='./data',
    train=True,
    transform=None,
    target_transform=None,
    download=True)
```

## 模块

模块本身是一个类nn.Module，PyTorch的模型通过继承该类，在类的内部定义子模块的实例化，通过前向计算调用子模块，最后实现深度学习模型的搭建

```python
import torch.nn as nn
class LinearModel(nn.Module):
    def __init__(self,ndim):
        super(LinearModel,self).__init__()
        self.ndim = ndim
        # 需要使用nn.Parameter来包装这些参数，使之成为子模块（仅仅由参数构成的子模块），这是因为在后续训练的时候需要对参数进行优化，只有将张量转换为参数才能在后续的优化过程中被优化器访问到。
        self.weight = nn.Parameter(torch.randn(ndim,1)) # 定义权重
        self.bias = nn.Parameter(torch.randn(1)) # 定义偏置
    def forward(self,x):
        # y = Wx +b
        return x.mm(self.weight) + self.bias
```


```python
class Module:
    dump_patches: bool = False
    _version: int = 1
    training: bool      # 本网络是否正在训练
    _is_full_backward_hook: Optional[bool]
​
    def __init__(self):
        """
        Initializes internal Module state, shared by both nn.Module and ScriptModule.
        """
        torch._C._log_api_usage_once("python.nn_module")
​
        self.training = True
        self._parameters = OrderedDict()            # 在训练过程中会随着 BP 而更新的参数
        self._buffers = OrderedDict()               # 在训练过程中不会随着 BP 而更新的参数
        self._non_persistent_buffers_set = set()
        self._backward_hooks = OrderedDict()
        self._is_full_backward_hook = None
        self._forward_hooks = OrderedDict()
        self._forward_pre_hooks = OrderedDict()
        self._state_dict_hooks = OrderedDict()
        self._load_state_dict_pre_hooks = OrderedDict()
        self._modules = OrderedDict()       # 本网络下属的子模块，采取迭代的方式进行定义

```

当一个模型的网络结构被定义之后，self._parameters 和 self._buffers的组合是一个模型的具体状态。移动模型到GPU这个动作的背后究竟做了哪些操作？调用 cuda 或者 to 方法来移动模型到GPU，其实就是把模型的self._parameters 和 self._buffers 移动到 GPU，并没有对 self._modules 进行移动。这个移动过程是递归调用的，是把模型每个叶子都移动到了 GPU 之上。PS： 没懂

## 部署

[如何部署 PyTorch 模型](https://zhuanlan.zhihu.com/p/344364948) TorchServe

## 自动微分

[一文详解pytorch的“动态图”与“自动微分”技术 - DL-Practise的文章 - 知乎](https://zhuanlan.zhihu.com/p/351687500)
1. 我们手工编写的forward函数就是pytorch前向运行的动态图。当代码执行到哪一句的时候，网络就运行到哪一步。
2. 实际上pytorch并没有显式的去构建一个所谓的动态图，本质就是按照forward的代码执行流程走了一遍而已。那么对于反向传播，因为我们没有构建反向传播的代码，**pytorch也就无法像前向传播那样，通过我们手动编写的代码执行流进行反向传播**。那么pytorch是如何实现精确的反向传播的呢？其实最大的奥秘就藏在tensor的grad_fn属性里面。Pytorch中的tensor对象都有一个叫做grad_fn的属性，它实际上是一个链表。grad_fn是python层的封装，其实现对应的就是pytorch源码在autograd下面的node对象，为C++实现
3. Pytorch中的tensor有两种产生方式，一种是凭空创建的，例如一些op里面的params，训练的images，这些tensor，他们不是由其他tensor计算得来的，而是通过torch.zeros(),torch.ones(),torch.from_numpy()等凭空创建出来的。另外一种产生方式是由某一个tensor经过一个op计算得到，例如tensor a通过conv计算得到tensor b。其实这两种op创建方式对应的就是**leaf节点（叶子节点）和非leaf（非叶子节点）**。非leaf节点的grad_fn是有值的，因为它的梯度需要继续向后传播给创建它的那个节点。而leaf节点的grad_fn为None，因为他们不是由其他节点创建而来，他们的梯度不需要继续反向传播。
4. tensor的grad_fn是如何构建的？无论是我们自己编写的上层代码，还是在pytorch底层的op实现里面，并没有显示的去创建grad_fn，那么它是在何时，又是如何组装的？Pytorch会对所有底层算子进一个二次封装，在做完正常的op前向之后，增加了grad_fn的设置，next_functions的设置等流程。

    ![](/public/upload/machine/tensor_set_grad_fn.png)



一个运行中的Tensor
```
Q = {Tensor} 
 data = {Tensor} tensor(-12.)           # 该张量的数据
 device = {device} cpu                      # 存放该张量的设备类型
 dtype = {dtype} torch.float32          # 张量的数据类型
 grad = {NoneType} None                 # 保存数据data对应的梯度，和数据data的形状一样
 grad_fn = {SubBackward0} 
  metadata = {dict: 0} {}
  next_functions = {tuple: 2} 
   0 = {tuple: 2} (<MulBackward0 object at 0x000001F9547A5848>, 0)
   1 = {tuple: 2} (<PowBackward0 object at 0x000001F9547A53C8>, 0)
   __len__ = {int} 2
  requires_grad = {bool} True           # 表示该Tensor是否需要求导，如否，在反向传播过程中，该节点所在的子图会被排除在计算过程之外。
 is_cuda = {bool} False 
 is_leaf = {bool} False                 # 记录该张量是否是叶子节点
 is_meta = {bool} False
 is_mkldnn = {bool} False
 is_mlc = {bool} False
 is_quantized = {bool} False
 is_sparse = {bool} False
 is_sparse_csr = {bool} False
 is_vulkan = {bool} False
 is_xpu = {bool} False
 layout = {layout} torch.strided
 name = {NoneType} None
 names = {tuple: 0} ()
 ndim = {int} 0
 output_nr = {int} 0
 requires_grad = {bool} True
 shape = {Size: 0} torch.Size([])

作者：罗西的思考
链接：https://juejin.cn/post/7020341694629576734
来源：稀土掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
```


## 其它

PyTorch Hub，通过PyTorch Hub，用户可以获得一系列预训练的深度学习模型，主要包括计算机视觉、自然语言处理、生成式模型和音频模型等，这些预训练模型的出现能有效地加快用户开发新型的深度学习模型，方便用户构建基线模型和复现深度学习模型的效果。

[PyTorch Lightning工具学习](https://mp.weixin.qq.com/s/LeUjxmGHpIrUsLDBmKNrdA)Pytorch Lightning是在Pytorch基础上进行封装的库(可以理解为keras之于tensorflow)，为了让用户能够脱离PyTorch一些繁琐的细节，专注于核心代码的构建，提供了许多实用工具，可以让实验更加高效。 文中以MNIST 为例列出了 使用原生pytorch 和PyTorch Lightning 的代码对比。 

![](/public/upload/machine/pytorch_lighting.png)

[PyTorch深度学习技术生态](https://mp.weixin.qq.com/s/3X6A8nNZHOgGELiSQsGkcQ)



